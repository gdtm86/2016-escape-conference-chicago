{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Apache Spark Logo](https://s3-us-west-2.amazonaws.com/gmedasani-chicago-escape-conference/setup/images/spark-logo.png) \n",
    "![Machine Learning Image](https://s3-us-west-2.amazonaws.com/gmedasani-chicago-escape-conference/setup/images/machine-learning.png)\n",
    "\n",
    "\n",
    "# Machine Learing - Linear Regression\n",
    "\n",
    "This section covers a commom supervised learning pipeline, using a subset of the [Million Song Dataset](http://labrosa.ee.columbia.edu/millionsong/) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Our goal is to train a linear regression model to predict the release year of a song given a set of audio features.\n",
    "\n",
    "\n",
    "This exercise will cover: \n",
    "\n",
    "* Part 1: Explore the dataset\n",
    "* Part 2: Feature Engineering\n",
    "* Part 3: Create and evaluate a baseline model\n",
    "* Part 4: Create a Linear Regression Model\n",
    "* Part 5: Choose the best model by Hyperparamter tuning\n",
    "\n",
    "\n",
    "Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup\n",
    "\n",
    "* Check if spark context is available\n",
    "* Import needed libraries\n",
    "* Define the dataset path (Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7f0c9b219c10>\n"
     ]
    }
   ],
   "source": [
    "print sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student1/2016-escape-conference-chicago/datasets/millionsong.txt\n"
     ]
    }
   ],
   "source": [
    "# Set the value of the studentid to your studentid provided in the instructions'\n",
    "studentid = 'student1'\n",
    "filepath = '/home/'+studentid+'/2016-escape-conference-chicago/datasets/millionsong.txt'\n",
    "print filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "* Define the schema for the dataframe\n",
    "* Using SqlContext, create a millionsongs dataframe\n",
    "* Explore the millionsongs dataframe\n",
    "\n",
    "#### Define the schema for the millionsongs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType,StructField,DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "millionSongSchema = StructType([\n",
    "        StructField(\"year\", DoubleType(), True),\n",
    "        StructField(\"f1\", DoubleType(), True),\n",
    "        StructField(\"f2\", DoubleType(), True),\n",
    "        StructField(\"f3\", DoubleType(), True),\n",
    "        StructField(\"f4\", DoubleType(), True),\n",
    "        StructField(\"f5\", DoubleType(), True),\n",
    "        StructField(\"f6\", DoubleType(), True),\n",
    "        StructField(\"f7\", DoubleType(), True),\n",
    "        StructField(\"f8\", DoubleType(), True),\n",
    "        StructField(\"f9\", DoubleType(), True),\n",
    "        StructField(\"f10\", DoubleType(), True),\n",
    "        StructField(\"f11\", DoubleType(), True),\n",
    "        StructField(\"f12\", DoubleType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using sqlContext, create a million songs dataframe\n",
    "\n",
    "We are using a Spark packagge called [spark-csv: CSV Data Source for Spark](http://spark-packages.org/package/databricks/spark-csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "millionsongs_raw_df = (sqlContext.read.format('com.databricks.spark.csv')\n",
    "                        .options(header='false', inferschema='true')\n",
    "                        .load(filepath, schema = millionSongSchema)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the millionsongs dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "millionsongs_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2001.0, f1=0.884123733793, f2=0.610454259079, f3=0.600498416968, f4=0.474669212493, f5=0.247232680947, f6=0.357306088914, f7=0.344136412234, f8=0.339641227335, f9=0.600858840135, f10=0.425704689024, f11=0.60491501652, f12=0.419193351817),\n",
       " Row(year=2001.0, f1=0.854411946129, f2=0.604124786151, f3=0.593634078776, f4=0.495885413963, f5=0.266307830936, f6=0.261472105188, f7=0.506387076327, f8=0.464453565511, f9=0.665798573683, f10=0.542968988766, f11=0.58044428577, f12=0.445219373624),\n",
       " Row(year=2001.0, f1=0.908982970575, f2=0.632063159227, f3=0.557428975183, f4=0.498263761394, f5=0.276396052336, f6=0.312809861625, f7=0.448530069406, f8=0.448674249968, f9=0.649791323916, f10=0.489868662682, f11=0.591908113534, f12=0.4500023818),\n",
       " Row(year=2001.0, f1=0.842525219898, f2=0.561826888508, f3=0.508715259692, f4=0.443531142139, f5=0.296733836002, f6=0.250213568176, f7=0.488540873206, f8=0.360508747659, f9=0.575435243185, f10=0.361005878554, f11=0.678378718617, f12=0.409036786173),\n",
       " Row(year=2001.0, f1=0.909303285534, f2=0.653607720915, f3=0.585580794716, f4=0.473250503005, f5=0.251417011835, f6=0.326976795524, f7=0.40432273022, f8=0.371154511756, f9=0.629401917965, f10=0.482243251755, f11=0.566901413923, f12=0.463373691946)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millionsongs_raw_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6724"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millionsongs_raw_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-------------------+-------------------+\n",
      "|summary|              year|                 f1|                 f2|                 f3|\n",
      "+-------+------------------+-------------------+-------------------+-------------------+\n",
      "|  count|              6724|               6724|               6724|               6724|\n",
      "|   mean|1975.7850981558597| 0.6619961470749578| 0.5339408278096173|  0.469804021937418|\n",
      "| stddev|  21.4198604561239|0.15636089565238775|0.12683383787039013|0.09394144758944296|\n",
      "|    min|            1922.0|                0.0|                0.0|                0.0|\n",
      "|    max|            2011.0|                1.0|                1.0|                1.0|\n",
      "+-------+------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "millionsongs_raw_df.describe(['year','f1','f2','f3']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering\n",
    "\n",
    "As part of the feature enginering, we will perform following two steps\n",
    "\n",
    "* Shift the labels(year)\n",
    "* Create a dataframe with Vectorized features\n",
    "* Create Interaction features and polynomial features\n",
    "* Create Train, Test and Validation datasets\n",
    "\n",
    "#### Shift Lables\n",
    "\n",
    "As we just saw, the lables are years in the 1900s and 2000s. In learning problems, it is often natural to shift lables such that they start from zero. \n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum year is : 1922.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, min, max\n",
    "minYear = millionsongs_raw_df.select(min('year')).collect()[0].asDict().values()[0]\n",
    "print 'Minimum year is : '+str(minYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "millionsongs_shifted_df = millionsongs_raw_df.withColumn('year', millionsongs_raw_df.year - minYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=79.0, f1=0.884123733793, f2=0.610454259079, f3=0.600498416968, f4=0.474669212493, f5=0.247232680947, f6=0.357306088914, f7=0.344136412234, f8=0.339641227335, f9=0.600858840135, f10=0.425704689024, f11=0.60491501652, f12=0.419193351817),\n",
       " Row(year=79.0, f1=0.854411946129, f2=0.604124786151, f3=0.593634078776, f4=0.495885413963, f5=0.266307830936, f6=0.261472105188, f7=0.506387076327, f8=0.464453565511, f9=0.665798573683, f10=0.542968988766, f11=0.58044428577, f12=0.445219373624),\n",
       " Row(year=79.0, f1=0.908982970575, f2=0.632063159227, f3=0.557428975183, f4=0.498263761394, f5=0.276396052336, f6=0.312809861625, f7=0.448530069406, f8=0.448674249968, f9=0.649791323916, f10=0.489868662682, f11=0.591908113534, f12=0.4500023818),\n",
       " Row(year=79.0, f1=0.842525219898, f2=0.561826888508, f3=0.508715259692, f4=0.443531142139, f5=0.296733836002, f6=0.250213568176, f7=0.488540873206, f8=0.360508747659, f9=0.575435243185, f10=0.361005878554, f11=0.678378718617, f12=0.409036786173),\n",
       " Row(year=79.0, f1=0.909303285534, f2=0.653607720915, f3=0.585580794716, f4=0.473250503005, f5=0.251417011835, f6=0.326976795524, f7=0.40432273022, f8=0.371154511756, f9=0.629401917965, f10=0.482243251755, f11=0.566901413923, f12=0.463373691946)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millionsongs_shifted_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe with vectorized features\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler\n",
    "\n",
    "A feature transformer that merges multiple columns into a vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12']\n",
    "target = 'year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=features_list,\n",
    "    outputCol=\"features\")\n",
    "millionsongs_df = assembler.transform(millionsongs_shifted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "millionsongs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=79.0, f1=0.884123733793, f2=0.610454259079, f3=0.600498416968, f4=0.474669212493, f5=0.247232680947, f6=0.357306088914, f7=0.344136412234, f8=0.339641227335, f9=0.600858840135, f10=0.425704689024, f11=0.60491501652, f12=0.419193351817, features=DenseVector([0.8841, 0.6105, 0.6005, 0.4747, 0.2472, 0.3573, 0.3441, 0.3396, 0.6009, 0.4257, 0.6049, 0.4192])),\n",
       " Row(year=79.0, f1=0.854411946129, f2=0.604124786151, f3=0.593634078776, f4=0.495885413963, f5=0.266307830936, f6=0.261472105188, f7=0.506387076327, f8=0.464453565511, f9=0.665798573683, f10=0.542968988766, f11=0.58044428577, f12=0.445219373624, features=DenseVector([0.8544, 0.6041, 0.5936, 0.4959, 0.2663, 0.2615, 0.5064, 0.4645, 0.6658, 0.543, 0.5804, 0.4452]))]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millionsongs_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create interaction features and Polynomial features\n",
    "\n",
    "Perform feature expansion in a polynomial space. As said in wikipedia of Polynomial Expansion, which is available at http://en.wikipedia.org/wiki/Polynomial_expansion, “In mathematics, an expansion of a product of sums expresses it as a sum of products by using the fact that multiplication distributes over addition”. Take a 2-variable feature vector as an example: (x, y), if we want to expand it with degree 2, then we get (x, x * x, y, x * y, y * y).\n",
    "\n",
    "http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.PolynomialExpansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "px = PolynomialExpansion(degree=2, inputCol=\"features\", outputCol=\"polyFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "millionsongs_poly_df = px.transform(millionsongs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- polyFeatures: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "millionsongs_poly_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=79.0, f1=0.884123733793, f2=0.610454259079, f3=0.600498416968, f4=0.474669212493, f5=0.247232680947, f6=0.357306088914, f7=0.344136412234, f8=0.339641227335, f9=0.600858840135, f10=0.425704689024, f11=0.60491501652, f12=0.419193351817, features=DenseVector([0.8841, 0.6105, 0.6005, 0.4747, 0.2472, 0.3573, 0.3441, 0.3396, 0.6009, 0.4257, 0.6049, 0.4192]), polyFeatures=DenseVector([0.8841, 0.7817, 0.6105, 0.5397, 0.3727, 0.6005, 0.5309, 0.3666, 0.3606, 0.4747, 0.4197, 0.2898, 0.285, 0.2253, 0.2472, 0.2186, 0.1509, 0.1485, 0.1174, 0.0611, 0.3573, 0.3159, 0.2181, 0.2146, 0.1696, 0.0883, 0.1277, 0.3441, 0.3043, 0.2101, 0.2067, 0.1634, 0.0851, 0.123, 0.1184, 0.3396, 0.3003, 0.2073, 0.204, 0.1612, 0.084, 0.1214, 0.1169, 0.1154, 0.6009, 0.5312, 0.3668, 0.3608, 0.2852, 0.1486, 0.2147, 0.2068, 0.2041, 0.361, 0.4257, 0.3764, 0.2599, 0.2556, 0.2021, 0.1052, 0.1521, 0.1465, 0.1446, 0.2558, 0.1812, 0.6049, 0.5348, 0.3693, 0.3633, 0.2871, 0.1496, 0.2161, 0.2082, 0.2055, 0.3635, 0.2575, 0.3659, 0.4192, 0.3706, 0.2559, 0.2517, 0.199, 0.1036, 0.1498, 0.1443, 0.1424, 0.2519, 0.1785, 0.2536, 0.1757]))]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millionsongs_poly_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train, Test and Validation datasets\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = millionsongs_df.randomSplit(weights=[0.7,0.15,0.15], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_poly_df, valid_poly_df, test_poly_df = millionsongs_poly_df.randomSplit(weights=[0.7,0.15,0.15], seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Dataset size: 4765\n",
      "Valid Dataset size: 981\n",
      "Test Dataset size: 978\n"
     ]
    }
   ],
   "source": [
    "print \"Traning Dataset size: \" + str(train_df.count())\n",
    "print \"Valid Dataset size: \" + str(valid_df.count())\n",
    "print \"Test Dataset size: \" + str(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly Traning Dataset size: 4765\n",
      "Poly Valid Dataset size: 981\n",
      "Poly Test Dataset size: 978\n"
     ]
    }
   ],
   "source": [
    "print \"Poly Traning Dataset size: \" + str(train_poly_df.count())\n",
    "print \"Poly Valid Dataset size: \" + str(valid_poly_df.count())\n",
    "print \"Poly Test Dataset size: \" + str(test_poly_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create a Baseline model\n",
    "\n",
    "In this section, we will create a baseline model and evaluate that model with validation and test datasets. \n",
    "\n",
    "* Create an average model\n",
    "* Calculate the RMSE on the validation and test datasets based on the predictions by average model\n",
    "\n",
    "#### Average model\n",
    "\n",
    "A very simple yet natural baseline model is one where we always make the same prediction independent for a given data point, using the average label in the training set as the constant prediction value. Compute this value, which is the average(shifted) song year for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.766841553\n"
     ]
    }
   ],
   "source": [
    "averageTrainYear = train_df.select(mean('year')).collect()[0].asDict().values()[0]\n",
    "print averageTrainYear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root mean squared error\n",
    "\n",
    "We naturally would like to see how well this naive baseline performs. We will use root mean squared error(RMSE) for evaluation purposes.\n",
    "\n",
    "Creates a Column of literal value. https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lit\n",
    "\n",
    "Evaluator for Regression, which expects two input columns: prediction and label. Supports the following metrics.\n",
    "* mse\n",
    "* rmse\n",
    "* r2\n",
    "* mae\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_train_baseModel = train_df.withColumn('year_predicted', pyspark.sql.functions.lit(averageTrainYear))\n",
    "predictions_valid_baseModel = valid_df.withColumn('year_predicted', pyspark.sql.functions.lit(averageTrainYear))\n",
    "predictions_test_baseModel = test_df.withColumn('year_predicted', pyspark.sql.functions.lit(averageTrainYear))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the year_predicted column, which is the averageTrainYear repeated for every record in the training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- year_predicted: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train_baseModel.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=8.0, f1=0.169859883053, f2=0.347163029706, f3=0.310357993388, f4=0.183068614542, f5=0.319387467117, f6=0.615347306265, f7=0.234347964383, f8=0.655487922947, f9=0.312231493679, f10=0.622081983507, f11=0.365167752259, f12=0.401388756294, features=DenseVector([0.1699, 0.3472, 0.3104, 0.1831, 0.3194, 0.6153, 0.2343, 0.6555, 0.3122, 0.6221, 0.3652, 0.4014]), year_predicted=53.766841553),\n",
       " Row(year=11.0, f1=0.530393989851, f2=0.205627239023, f3=0.534139321378, f4=0.404864005298, f5=0.122195907889, f6=0.660395414619, f7=0.267234514594, f8=0.525681714294, f9=0.458256825104, f10=0.503793687198, f11=0.568304391237, f12=0.395315655212, features=DenseVector([0.5304, 0.2056, 0.5341, 0.4049, 0.1222, 0.6604, 0.2672, 0.5257, 0.4583, 0.5038, 0.5683, 0.3953]), year_predicted=53.766841553)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_baseModel.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate the training, validation and test RMSE errors for the average baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='year', predictionCol='year_predicted', metricName='rmse')\n",
    "trainError_baseModel = evaluator.evaluate(predictions_train_baseModel)\n",
    "validError_baseModel = evaluator.evaluate(predictions_valid_baseModel)\n",
    "testError_baseModel = evaluator.evaluate(predictions_test_baseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Trainig Error : 21.3205877722\n",
      "Baseline Model Validation Error : 21.9055648831\n",
      "Baseline Model Test Error is : 21.3987891177\n"
     ]
    }
   ],
   "source": [
    "print \"Baseline Model Trainig Error : \"+ str(trainError_baseModel)\n",
    "print \"Baseline Model Validation Error : \"+ str(validError_baseModel)\n",
    "print \"Baseline Model Test Error is : \"+ str(testError_baseModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 4: Create a Linear Regression Model\n",
    "\n",
    "We now have some idea about the validation and test errors from baseline. But we should be able to do a little better by using a linear regression model.\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression\n",
    "\n",
    "Here we will use the L-BFGS solver\n",
    "\n",
    "http://spark.apache.org/docs/latest/mllib-optimization.html#limited-memory-bfgs-l-bfgs\n",
    "\n",
    "** Limited-memory BFGS (L-BFGS)**\n",
    "\n",
    "L-BFGS is an optimization algorithm in the family of quasi-Newton methods to solve the optimization problems of the form minw∈ℝdf(w)minw∈Rdf(w). The L-BFGS method approximates the objective function locally as a quadratic without evaluating the second partial derivatives of the objective function to construct the Hessian matrix. The Hessian matrix is approximated by previous gradient evaluations, so there is no vertical scalability issue (the number of training features) when computing the Hessian matrix explicitly in Newton’s method. As a result, L-BFGS often achieves rapider convergence compared with other first-order optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg1=0.0001\n",
    "lr1 = LinearRegression(featuresCol='features', labelCol='year',\n",
    "    maxIter=5, regParam=reg1, solver=\"l-bfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = lr1.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.48121033560951"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([23.7556, 27.1228, -66.3133, 38.2803, -11.8044, -36.3591, 47.4329, -24.3628, 6.0349, -2.5097, 1.2619, -19.0812])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions on the validation data and test data\n",
    "\n",
    "Once we transform the input DataFrame using the fitted model, we will see a new column called 'prediction' in the result DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_train_model1 = model1.transform(train_df)\n",
    "predictions_valid_model1 = model1.transform(valid_df)\n",
    "predictions_test_model1 = model1.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train_model1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=8.0, prediction=16.48691352031952, features=DenseVector([0.1699, 0.3472, 0.3104, 0.1831, 0.3194, 0.6153, 0.2343, 0.6555, 0.3122, 0.6221, 0.3652, 0.4014])),\n",
       " Row(year=11.0, prediction=21.825975664529885, features=DenseVector([0.5304, 0.2056, 0.5341, 0.4049, 0.1222, 0.6604, 0.2672, 0.5257, 0.4583, 0.5038, 0.5683, 0.3953]))]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train_model1.select('year','prediction','features').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator1 = RegressionEvaluator(labelCol='year', predictionCol='prediction', metricName='rmse')\n",
    "trainError_model1 = evaluator1.evaluate(predictions_train_model1)\n",
    "validError_model1 = evaluator1.evaluate(predictions_valid_model1)\n",
    "testError_model1 = evaluator1.evaluate(predictions_test_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model1 Trainig Error : 15.4646109534\n",
      "Linear Regression Model1 Validation Error : 16.3166845653\n",
      "Linear Regression Model1 Test Error is : 15.6200094335\n"
     ]
    }
   ],
   "source": [
    "print \"Linear Regression Model1 Trainig Error : \"+ str(trainError_model1)\n",
    "print \"Linear Regression Model1 Validation Error : \"+ str(validError_model1)\n",
    "print \"Linear Regression Model1 Test Error is : \"+ str(testError_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Choose the best model by Hyperparamter tuning\n",
    "\n",
    "\n",
    "* Perform grid search fo find a good regularization parameter\n",
    "* Report the test dataset error using the best model selected using the Hyperparameter optimization.\n",
    "\n",
    "We are already outperforming the baseline on the validation setby almost 5 years on average, but let's see if we can do better by selecting a best model based with hyperparameter tuning. \n",
    "\n",
    "Hyperparameter Tuning/Optimization or model selection is the problem of choosing a set of hyperparameters for a learning algorithm, usually with the goal of optimizing a measure of the algorithm's performance on an independent data set such as Validation dataset. \n",
    "https://en.wikipedia.org/wiki/Hyperparameter_optimization\n",
    "\n",
    "\n",
    "For this model selection, the hyperparameter we are tuning is regularization parameter. Regularization type we are using is L2 norm.\n",
    "\n",
    "#### Perform grid search to find a good regulization parameter. \n",
    "\n",
    "We will search in the hyperparameter space with values 1e-100,1e-10,1e-5,1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.2709818641\n",
      "16.2709818641\n",
      "16.270982259\n",
      "16.2709858129\n",
      "16.3117147103\n",
      "============\n",
      "Validation RMSE Baseline Model:21.9055648831\n",
      "Validation RMSE Model 1: 16.3166845653\n",
      "Validation RMSE Best Model: 16.2709818641\n"
     ]
    }
   ],
   "source": [
    "bestRMSE = validError_model1\n",
    "bestRegParam = reg1\n",
    "bestModel = model1\n",
    "\n",
    "numIters = 100\n",
    "evaluator2 = RegressionEvaluator(labelCol='year', predictionCol='prediction', metricName='rmse')\n",
    "for reg in [1e-100,1e-10,1e-5,0.0001,1.0]:\n",
    "    \n",
    "    lr = LinearRegression(featuresCol='features', labelCol='year',\n",
    "                                maxIter=numIters, regParam=reg, solver=\"l-bfgs\")\n",
    "    model = lr.fit(train_df)\n",
    "    predictions_valid_model = model.transform(valid_df)\n",
    "    \n",
    "    # Evaluate the validation error using the current model\n",
    "    rmseValGrid = evaluator2.evaluate(predictions_valid_model)\n",
    "    print rmseValGrid\n",
    "    \n",
    "    # Compare the current model's RMSE vs best model's RMSE\n",
    "    if rmseValGrid < bestRMSE:\n",
    "        bestRMSE = rmseValGrid\n",
    "        bestRegParam = reg\n",
    "        bestModel = model\n",
    "rmseValLRGrid = bestRMSE\n",
    "\n",
    "print '============'\n",
    "print 'Validation RMSE Baseline Model:'+str(validError_baseModel)\n",
    "print 'Validation RMSE Model 1: '+str(validError_model1)\n",
    "print 'Validation RMSE Best Model: '+str(rmseValLRGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.45458727828077"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([25.2375, 25.1789, -67.2705, 53.7004, -13.0249, -47.7873, 34.2649, -22.7609, 3.4272, -5.475, -12.3466, -12.7098])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-100"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestRegParam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report the test dataset error using the best model selected using the Hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_test_bestModel = bestModel.transform(test_df)\n",
    "testError_bestModel = evaluator2.evaluate(predictions_test_bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Best Model Test Error is : 15.5800681484\n"
     ]
    }
   ],
   "source": [
    "print \"Linear Regression Best Model Test Error is : \"+ str(testError_bestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Baseline Model Test Error is : 21.3987891177\n",
      "Linear Regression Model1 Test Error is : 15.6200094335\n",
      "Linear Regression Best Model Test Error is : 15.5800681484\n"
     ]
    }
   ],
   "source": [
    "print \"Average Baseline Model Test Error is : \"+ str(testError_baseModel)\n",
    "print \"Linear Regression Model1 Test Error is : \"+ str(testError_model1)\n",
    "print \"Linear Regression Best Model Test Error is : \"+ str(testError_bestModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** As we can see from the above results, we were able to improve our prediction results from the baseline average model by a huge margin.**\n",
    "\n",
    "\n",
    "** Further we can build additional models using the polynomial features to improve the model's predictions and reduce test errorts**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
